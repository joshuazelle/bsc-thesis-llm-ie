{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r content_df # get the df with html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = content_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0, hernan's function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hernan's function\n",
    "import re\n",
    "\n",
    "\n",
    "def clean_html(html_content):\n",
    "    try:\n",
    "        html_content = re.sub(\n",
    "            r\"<(script|style).*?>.*?</\\1>\", \"\", html_content, flags=re.DOTALL\n",
    "        )  # Remove script and style elements\n",
    "        html_content = re.sub(\n",
    "            r'&{2,}.*?[\"\\'>]', \"\", html_content\n",
    "        )  # Remove JavaScript-like patterns and similar snippets Yes, it's needed, because we still had trash\n",
    "        text = re.sub(\n",
    "            r\"<[^>]+>\", \"\", html_content\n",
    "        )  # Remove all remaining HTML tags but leaving stuff between tags\n",
    "        text = re.sub(\n",
    "            r\"&([a-z0-9]+|#[0-9]{1,6}|#x[0-9a-f]{1,6});\", \"\", text\n",
    "        )  # Replace HTML entities with normal chars\n",
    "        text = \" \".join(text.split())\n",
    "        return text\n",
    "    except Exception as e:\n",
    "        print(\"this is not html\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"regex\"] = df[\"content\"].apply(clean_html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"regex\"].apply(len).median()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1, first iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first iteration:\n",
    "import re\n",
    "\n",
    "\n",
    "def clean_html_1(html_content):\n",
    "    try:\n",
    "        # Remove content within script or style tags.\n",
    "        html_content = re.sub(\n",
    "            r\"<(script|style).*?>.*?</\\1>\", \"\", html_content, flags=re.DOTALL\n",
    "        )\n",
    "        # Remove JavaScript-like patterns and other similar snippets.\n",
    "        html_content = re.sub(r'&{2,}.*?[\"\\'>]', \"\", html_content)\n",
    "        # Remove all remaining HTML tags but leave the content between tags.\n",
    "        text = re.sub(r\"<[^>]+>\", \"\", html_content)\n",
    "        # Replace HTML entities with normal characters.\n",
    "        text = re.sub(r\"&([a-z0-9]+|#[0-9]{1,6}|#x[0-9a-f]{1,6});\", \"\", text)\n",
    "        # Remove content within curly braces, including the braces themselves.\n",
    "        text = re.sub(r\"\\{.*?\\}\", \"\", text)\n",
    "        # Normalize whitespace to single spaces.\n",
    "        text = \" \".join(text.split())\n",
    "        return text\n",
    "    except Exception as e:\n",
    "        print(\"Error processing HTML: {}\".format(e))\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"regex1\"] = df[\"content\"].apply(clean_html_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"regex1\"].apply(len).median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by 'ascii_id_company' and aggregate the other columns\n",
    "df_grouped = (\n",
    "    df.drop([\"content\"], axis=\"columns\")\n",
    "    .groupby(\"ascii_id_company\")\n",
    "    .agg(\n",
    "        {\n",
    "            \"src_url\": lambda x: list(x),  # Convert all src_url values to a list\n",
    "            \"regex\": lambda x: \" \".join(x),  # Join all extracted text with a space\n",
    "            \"regex1\": lambda x: \" \".join(x),  # Join all extracted text with a space\n",
    "        }\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "df_grouped = df_grouped.rename(columns={\"src_url\": \"url_list\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = df_grouped.iloc[16][\n",
    "    \"regex1\"\n",
    "]  # this one index 16 is a good case to test on as it somehow still collects code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import textwrap\n",
    "\n",
    "\n",
    "def print_wrapped(text, width=80):\n",
    "    print(\"\\n\".join(textwrap.wrap(text, width=width)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_wrapped(text, width=120)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Notes:\n",
    "\n",
    "still not removed the code from curly braces..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ascii_rs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
