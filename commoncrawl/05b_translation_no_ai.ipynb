{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install googletrans\n",
    "# pip install google-cloud-translate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r df_extr_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_extr_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langdetect import detect, LangDetectException\n",
    "\n",
    "\n",
    "def detect_language(text):\n",
    "    try:\n",
    "        # Detect the language of the text\n",
    "        return detect(text)\n",
    "    except LangDetectException:\n",
    "        # Return a placeholder if language detection fails\n",
    "        return \"unknown\"\n",
    "\n",
    "\n",
    "# Apply the language detection function to the 'extr_text' column\n",
    "df[\"language\"] = df[\"extr_text\"].apply(detect_language)\n",
    "\n",
    "# Create a count table for the languages\n",
    "language_counts = df[\"language\"].value_counts()\n",
    "\n",
    "# Display the language count table\n",
    "language_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "\n",
    "def chunk_text_by_sentence(text, max_length=512):\n",
    "    sentences = sent_tokenize(text)\n",
    "    current_chunk = []\n",
    "    chunks = []\n",
    "\n",
    "    for sentence in sentences:\n",
    "        if len(\" \".join(current_chunk) + \" \" + sentence) > max_length:\n",
    "            chunks.append(\" \".join(current_chunk))\n",
    "            current_chunk = [sentence]\n",
    "        else:\n",
    "            current_chunk.append(sentence)\n",
    "\n",
    "    if current_chunk:\n",
    "        chunks.append(\" \".join(current_chunk))\n",
    "\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(text, target_language=\"en\"):\n",
    "    url = \"https://translation.googleapis.com/language/translate/v2\"\n",
    "    params = {\n",
    "        \"q\": text,\n",
    "        \"target\": target_language,\n",
    "        \"key\": api_key,  # Use the API key from the environment variable\n",
    "    }\n",
    "    response = requests.get(url, params=params)\n",
    "    result = response.json()\n",
    "\n",
    "    # Check for errors in the response\n",
    "    if \"error\" in result:\n",
    "        print(\"Error encountered:\", result[\"error\"])\n",
    "        return None\n",
    "\n",
    "    # Extracting the translated text\n",
    "    try:\n",
    "        translated_text = result[\"data\"][\"translations\"][0][\"translatedText\"]\n",
    "        return translated_text\n",
    "    except KeyError:\n",
    "        print(\"Unexpected response format:\", result)\n",
    "        return None\n",
    "\n",
    "\n",
    "# Example usage\n",
    "translated_text = translate_text_with_api_key(\"こんにちは、私の犬はかわいいです\", \"en\")\n",
    "print(translated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.DataFrame(\n",
    "    {\n",
    "        \"ascii_id_company\": [\"001\", \"002\", \"003\", \"004\"],\n",
    "        \"extr_text\": [\n",
    "            \"こんにちは、私の犬はかわいいです\",\n",
    "            \"这是一段中文文本\",\n",
    "            \"여기에 한국어 텍스트가 있습니다\",\n",
    "            \"hi baby\",\n",
    "        ],\n",
    "        \"language\": [\"ja\", \"zh-cn\", \"ko\", \"en\"],\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to apply on each row of the DataFrame\n",
    "def translate_row(row):\n",
    "    text = row[\"extr_text\"]\n",
    "    src_lang = row[\"language\"]\n",
    "    # Return None if the text is already in English\n",
    "    if src_lang == \"en\":\n",
    "        return None\n",
    "    else:\n",
    "        # If not English, chunk the text\n",
    "        chunks = chunk_text_by_sentence(text)\n",
    "\n",
    "        # Translate each chunk\n",
    "        translated_chunks = [translate(chunk) for chunk in chunks]\n",
    "\n",
    "        # Combine the translated chunks\n",
    "        translated_text = \" \".join(translated_chunks)\n",
    "\n",
    "        return translated_text\n",
    "\n",
    "\n",
    "# Apply the function to each row and create a new column with the translated texts\n",
    "df_test[\"translated\"] = df_test.apply(translate_row, axis=1)\n",
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now test real df\n",
    "\n",
    "df_test_real = df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_text_by_sentence(df_test_real.iloc[8, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_real[\"translated\"] = df_test_real.apply(translate_row, axis=1)\n",
    "df_test_real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ascii_rs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
